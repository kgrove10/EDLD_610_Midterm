---
title: "EDLD_610_Midterm"
author: "Andrew Edelblum, Kivalina Grove, and Ouafaa Hmaddi"
date: "4/22/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

library(rio)
library(tidyverse)
#install.packages("glue")
library(glue)
library(fs)
library(purrr)
library(janitor)
#install.packages("pracma")
library(pracma)
```

# EDLD 610 Midterm

### Part A: Data

The following function downloads data from the Oregon Department of education website on the number of students who scored in each performance category on the statewide assessment by race/ethnicity for every school in the state. It takes one argument, `year`, which must be a two digit integer from 15 to 18 (representing the 2014-15 to 2017-18 school years).

```{r download_file}
download_file <- function(year) {
    link <- glue::glue("https://www.oregon.gov/ode/educator-resources/assessment/TestResults20{year}/pagr_schools_ela_raceethnicity_{year-1}{year}.xlsx")
    rio::import(link, setclass = "tibble", na = c("-", "--", "*"))
}
```

1. Use the function above to download all the data for each of the past four school years and bind it into a single data frame, using a single function (i.e., one line of code).

```{r getdata}
data <- map_df(seq.int(from = 15, to = 18, by = 1), ~download_file(.x)) %>%
  clean_names()

#technically, this is two lines, but just because I wanted to clean the data in the same step, but we can separate out if you prefer!

data
```

Conduct some basic data cleaning to make your data file look like the following.

-  Filter for only student groups coded as `"White"` or `"Hispanic/Latino"`.
-  Select variables related to the number of students in each of the levels (1:4), and not percentages or collapsed levels.
-  Remove any row that has missing data in any of the *n* variables

```{r cleanData}
clean_data <- data %>%
  filter(student_group == "White" | student_group == "Hispanic/Latino") %>%
  select(-starts_with("percent"), 
         -ends_with("id"), 
         -subject,
         -number_proficient_level_3_or_4, 
         -number_proficient,
         -number_of_participants,
         -participation_rate) %>%
  drop_na(starts_with("number")) %>%
  gather(starts_with("number"), key = level, value = n) %>%
  separate(level, c(NA, NA, "level")) %>%
  mutate(level = as.double(level))

clean_data <- arrange(clean_data, academic_year, district, school, student_group, grade_level, level)

clean_data
```

2. Calculate the cumulative n for each school by student group, grade, and academic year. The result should look like the below. Hint, look at `?base::cumsum`.

```{r calcCumulative}
cumulative_data <- clean_data %>%
  group_by(academic_year, school, student_group, grade_level) %>%
  mutate(cn = cumsum(n))

cumulative_data[1:10, c(1, 3:8, 2)]
```

3. (3 points) Reformat the data so it looks like the below, removing n and filling by cn. Remove rows that have missing data for either student group.

```{r reformat}
school_data <- cumulative_data %>%
  select(-n) %>%
  spread(key = student_group, value = cn) %>%
  clean_names() %>%
  drop_na(hispanic_latino, white)

school_data
```

## Part B: Achievement Gaps

The function below estimates the average difference between two distributions in terms of an effect size. In this case, we are using the cumulative counts to approximate the empirical cumulative distribution function for each group. The distance between the distributions is then estimated and transformed to an effect size-like measure (for more information, see Ho & Reardon, 2012). The nice thing about this approach, is that we're able to obtain an effect size on the average difference in achievement between to groups of students as if we had the full, student level data even though we just have the counts within each category.

In the below function, the first argument supplied is the data source, followed by two string variables, the names of the reference and focal distributions, respectively (e.g., `"white"` and `"hispanic_latino"` in this case).

```{r gapFunction}
gap <- function(data, ref, foc) {
    x <- data[[ref]]
    y <- data[[foc]]
    auc <- pracma::trapz(y / y[length(x)],
                         x / x[length(x)])
    sqrt(2)*qnorm(auc)
}

### Example
gap(school_data[1:4, ], "white", "hispanic_latino")
```

1. Estimate an achievement gap effect size for every school in the state that reported data on both student groups (i.e., using the data we created above), for each grade level in each academic year.

```{r effect_size_all}
by_school_grade_year <- school_data %>% 
  group_by(district, school, academic_year) %>% 
  mutate(grade_level = recode(grade_level, 
                              "Grade 3" = "3", 
                              "Grade 4" = "4", 
                              "Grade 5" = "5",
                              "Grade 6" = "6",
                              "Grade 7" = "7",
                              "Grade 8" = "8",
                              "Grade HS (11)" = "11")) %>% 
  nest() %>% 
  slice(1:100)

gaps <- by_school_grade_year %>%
  unnest() %>% 
  group_by(district, school, grade_level, academic_year) %>% 
  nest()

gaps <- gaps %>% 
  mutate(gap = map_dbl(gaps$data, ~gap(.x, "white", "hispanic_latino")))

gaps <- gaps %>% 
  split(paste(gaps$district, gaps$school))

head(gaps)
```

2. The plot below shows the achievement gap estimates for one school by grade in Ashland School District during the 2017-18 school year. Produce a similar plot to the below (noting the school, academic year, and school district) for each of the first 100 unique school/year/district combinations. Hint - you'll want to use your effect size data from the previous question, nest it, then apply `slice(1:100)`. Note that the only reason I am asking you to slice the data frame is just to reduce run time. In reality, you would do this for all school/year/district combinations.

```{r plots}
library(colorblindr)
theme_set(theme_minimal())

plots <- lapply(gaps, function(x) {
  ggplot(x, aes(x = grade_level, y = gap)) +
    geom_bar(stat = "identity", aes(fill = gap)) +
    scale_fill_viridis_c(limits = c(-1.5, 1.5)) +
    geom_hline(yintercept = 0, color = "black", size = 1.5) +
    coord_flip() +
    labs(x = "Grade", y = "Effect Size", title = paste0("Achievement Gap Estimates: ", x$school), subtitle = "Students coded as White as compared to those coded as Hispanic/Latino", caption = paste0(x$academic_year, " School year, ", x$district, ", Oregon")) +
    theme(legend.position = "bottom",
          plot.title = element_text(face = "bold", hjust = 0.5), 
          plot.subtitle = element_text(hjust = 0.5),
          axis.title = element_text(face = "bold"),
          legend.key.width = unit(15, "mm"))
}) #updated this: added the necessary info (district, year, etc.) throughout the plot, adjusted the legend size and limits to be consistent throughout the plots.  Can't figure out the okabeito, so I went for my favorite color scheme, Viridis. :)  -kg
  
```

3. Save the plots into a "plots" directory. Make sure the file names are meaningful.

```{r save_plots}
dir.create(here::here("plots"))
filenames <- here::here("plots", 
                        paste0(map(gaps, ~.x$district[1]), "_", map(gaps, ~.x$school[1]), "_", map(gaps, ~.x$academic_year[1]), ".png")) #changed the file name to read school_year.png, since I thought that might be a little more meaningful?  -kg

walk2(filenames, plots, ggsave,
      width = 9.5, 
      height = 6.5,
      dpi = 500)

#for(i in seq_along(plots)) {
#    ggsave(filenames[i],
#           plots[[i]],
#           device = "png")
#}
```